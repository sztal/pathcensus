{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we present a set of basic tests of correctness of auxiliary\n",
    "classes and methods for conducting statistical inference based on ERGM\n",
    "null models implemented in `pathcensus` package. Everything we show here\n",
    "is also tested in the automated unit test suite, but we provide also\n",
    "a notebook-based confirmation as it is arguably much easier to follow.\n",
    "\n",
    "We focus on testing methods for estimating $p$-values of observed\n",
    "edge/node/graph structural coefficients relative to a null model\n",
    "(see notebook `2-null-models-test.ipynb` for more details).\n",
    "More conretely, we will consider the two following test cases:\n",
    "\n",
    "1. **Erdős–Rényi random graph.** In this case we expect all structural\n",
    "   coefficients on all levels (edges/nodes/graph) to be insignificant\n",
    "   with type I error rate not greater than $\\alpha$ when using a proper\n",
    "   adjustment for multiple testing (FDR procedure by Benjamini and Hochberg).\n",
    "2. **Random geometric graph (RGG),** As above but in this case we expect\n",
    "   similarity coefficients to be significantly larger than null model\n",
    "   expectations.\n",
    "\n",
    "For null model we will use Undirected Binary Configuration Model (UBCM)\n",
    "implemented in `pathcensus` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f913aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import igraph as ig\n",
    "from pathcensus import PathCensus\n",
    "from pathcensus.nullmodels import UBCM\n",
    "from pathcensus.inference import Inference\n",
    "from pathcensus.utils import set_seed\n",
    "\n",
    "def make_er_graph(n, dbar):\n",
    "    p = dbar / (n-1)\n",
    "    return ig.Graph.Erdos_Renyi(n, p=p, directed=False)\n",
    "\n",
    "def make_rgg(n, dbar):\n",
    "    radius = np.sqrt(dbar/(np.pi*(n-1)))\n",
    "    return ig.Graph.GRG(n, radius=radius, torus=True)\n",
    "\n",
    "# Global parameters\n",
    "# -----------------\n",
    "N_NODES   = 100     # number of nodes in random graphs\n",
    "KBAR      = 10      # expected average degree in random graphs\n",
    "ALPHA     = 0.01    # Upper bound for type I error rate with the FDR correction\n",
    "N_SAMPLES = 100     # number of samples used for estimating p-values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa28229",
   "metadata": {},
   "source": [
    "## Implementing statistical inference procedure\n",
    "\n",
    "In this project we conduct most of statistical inference based on simple\n",
    "exponential random graph models (ERGM), primarily different variants\n",
    "of the configuration model.\n",
    "\n",
    "Comparisons between observed values of various graph properties and\n",
    "expectations based on a null model are done according to the following scheme:\n",
    "\n",
    "1. Calculate observed values of graph statistics of interest and\n",
    "   index each node with its corresponding sufficient statistic(s).\n",
    "   Note that in the models we use sufficient statistics are always defined \n",
    "   for nodes (i.e. degree sequence in the standard configuration model).\n",
    "2. Sample $R$ randomized realization from a null model of choice.\n",
    "3. Index nodes in each randomized graph with values of their corresponding\n",
    "   sufficient statistics.\n",
    "4. Calculate graph statistics on $R$ randomized graph.\n",
    "5. Group simulated data by unique values of sufficient statistics.\n",
    "   In the case of nodes these are original sufficient statistics\n",
    "   (always defined for nodes in our case) and in the case of edges\n",
    "   these are unique combinations of sufficient statistics\n",
    "   (possibly coarse grained to avoid having too sparse data).\n",
    "   In the case of graph-level statistics no grouping is necessary.\n",
    "6. Compare observed values against the simulated values grouped\n",
    "   as described above where values for individual nodes/edges\n",
    "   are compared against distributions corresponding to their\n",
    "   values of sufficient statistics.\n",
    "\n",
    "**NOTE.** In this approach only one-sided tests are really possible.\n",
    "          Moreover, estimating p-values for edge-wise statistics\n",
    "          is currently problematic due to the need of coarse-graining\n",
    "          (and it is not yet clear what is the optimal strategy).\n",
    "\n",
    "In practice we usually implement the above procedure using a helper\n",
    "`Inference` class defined in `pathcensus` package which abstracts away\n",
    "most of tedious programming logic and requires the end user to implement\n",
    "only `statistics` method defining the actual graph statistics we want\n",
    "to calculate.\n",
    "\n",
    "Below we do this for the sake of the test of $p$-values estimation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832e1de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(graph, method, *args, **kwds):\n",
    "    \"\"\"Function computing graph statistics for which inference\n",
    "    is to be run.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph\n",
    "        A graph-like object.\n",
    "    method\n",
    "        Name of the method (string) defined on \n",
    "        :py:class:`pathcensus.PathCensus`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data\n",
    "        Data frame or series with grah statistics.\n",
    "    \"\"\"\n",
    "    paths = PathCensus(graph)\n",
    "    method = getattr(paths, method)\n",
    "    return method(*args, **kwds) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651e17d",
   "metadata": {},
   "source": [
    "## ER random graph\n",
    "\n",
    "In this case we expect all coefficients to be insignificant.\n",
    "We use one-sided tests checking with \"greater\" alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deefaa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sets seed of random, numpy and numba\n",
    "set_seed(371)\n",
    "\n",
    "graph = make_er_graph(N_NODES, KBAR)\n",
    "ubcm  = UBCM(graph)\n",
    "ubcm.fit()\n",
    "\n",
    "infer    = Inference(graph, ubcm, statistics)\n",
    "null_kws = dict(progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec1f1f",
   "metadata": {},
   "source": [
    "### Node-wise coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba3c02c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 22.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONE-TAILED TEST FOR NODE-WISE STRUCTURAL COEFFICIENTS\n",
    "data, null = infer.init_comparison(\n",
    "    n=N_SAMPLES,\n",
    "    method=\"coefs\",\n",
    "    mode=\"nodes\",\n",
    "    null_kws=null_kws\n",
    ")\n",
    "pvals = infer.estimate_pvalues(data, null, alternative=\"greater\")\n",
    "\n",
    "# CHECK IF THE FRACTION OF SIGNIFICANT VALUES\n",
    "# DOES NOT EXCEED ALPHA\n",
    "pvals_frac = (pvals.values <= ALPHA).mean()\n",
    "pvals_frac, pvals_frac <= ALPHA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cfb943",
   "metadata": {},
   "source": [
    "### Global coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf4b808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONE-TAILED TEST FOR GLOBAL STRUCTURAL COEFFICIENTS\n",
    "data, null = infer.init_comparison(\n",
    "    n=N_SAMPLES,\n",
    "    method=\"coefs\",\n",
    "    mode=\"global\",\n",
    "    null_kws=null_kws\n",
    ")\n",
    "pvals = infer.estimate_pvalues(data, null, alternative=\"greater\")\n",
    "\n",
    "# CHECK IF THE FRACTION OF SIGNIFICANT VALUES\n",
    "# DOES NOT EXCEED ALPHA\n",
    "pvals_frac = (pvals.values <= ALPHA).mean()\n",
    "pvals_frac, pvals_frac <= ALPHA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab78509b",
   "metadata": {},
   "source": [
    "## Random geometric graph\n",
    "\n",
    "In this case we expect significant presence of similarity\n",
    "and not significant results for complementarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e2aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(7171)\n",
    "\n",
    "graph = make_rgg(N_NODES, KBAR)\n",
    "ubcm  = UBCM(graph)\n",
    "ubcm.fit()\n",
    "\n",
    "infer = Inference(graph, ubcm, statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5965e0f",
   "metadata": {},
   "source": [
    "### Node-wise similarity\n",
    "\n",
    "In this case we expect a fraction of significant results greater than $\\alpha$\n",
    "using a one-sided test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55ee4fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9833333333333333, True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONE-TAILED TEST FOR NODE-WISE SIMILARITY COEFFICIENTS\n",
    "# (W0-COMPLEMENTARITY IS USED)\n",
    "data, null = infer.init_comparison(\n",
    "    n=N_SAMPLES,\n",
    "    method=\"simcoefs\",\n",
    "    mode=\"nodes\",\n",
    "    null_kws=null_kws\n",
    ")\n",
    "pvals = infer.estimate_pvalues(data, null, alternative=\"greater\")\n",
    "\n",
    "# CHECK IF THE FRACTION OF SIGNIFICANT VALUES\n",
    "# EXCEED ALPHA\n",
    "pvals_frac = (pvals.values <= ALPHA).mean()\n",
    "pvals_frac, pvals_frac > ALPHA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e6f64f",
   "metadata": {},
   "source": [
    "### Global similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8d8c329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 34.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONE-TAILED TEST FOR NODE-WISE SIMILARITY COEFFICIENTS\n",
    "# (W0-COMPLEMENTARITY IS USED)\n",
    "data, null = infer.init_comparison(\n",
    "    n=N_SAMPLES,\n",
    "    method=\"simcoefs\",\n",
    "    mode=\"global\",\n",
    "    null_kws=null_kws\n",
    ")\n",
    "pvals = infer.estimate_pvalues(data, null, alternative=\"greater\")\n",
    "\n",
    "# CHECK IF THE FRACTION OF SIGNIFICANT VALUES\n",
    "# EXCEED ALPHA\n",
    "pvals_frac = (pvals.values <= ALPHA).mean()\n",
    "pvals_frac, pvals_frac > ALPHA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c202decc",
   "metadata": {},
   "source": [
    "### Node-wise complementarity\n",
    "\n",
    "We expect no significant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa7c84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 39.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONE-TAILED TEST FOR EDGE-WISE SIMILARITY COEFFICIENTS\n",
    "# (W0-COMPLEMENTARITY IS USED)\n",
    "data, null = infer.init_comparison(\n",
    "    n=N_SAMPLES,\n",
    "    method=\"compcoefs\",\n",
    "    mode=\"nodes\",\n",
    "    null_kws=null_kws\n",
    ")\n",
    "pvals = infer.estimate_pvalues(data, null, alternative=\"greater\")\n",
    "\n",
    "# CHECK IF THE FRACTION OF SIGNIFICANT VALUES\n",
    "# EXCEED ALPHA\n",
    "pvals_frac = (pvals.values <= ALPHA).mean()\n",
    "pvals_frac, pvals_frac <= ALPHA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c97338c",
   "metadata": {},
   "source": [
    "### Global complementarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40bcbd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 31.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONE-TAILED TEST FOR EDGE-WISE SIMILARITY COEFFICIENTS\n",
    "# (W0-COMPLEMENTARITY IS USED)\n",
    "data, null = infer.init_comparison(\n",
    "    n=N_SAMPLES,\n",
    "    method=\"compcoefs\",\n",
    "    mode=\"global\",\n",
    "    null_kws=null_kws\n",
    ")\n",
    "pvals = infer.estimate_pvalues(data, null, alternative=\"greater\")\n",
    "\n",
    "# CHECK IF THE FRACTION OF SIGNIFICANT VALUES\n",
    "# EXCEED ALPHA\n",
    "pvals_frac = (pvals.values <= ALPHA).mean()\n",
    "pvals_frac, pvals_frac <= ALPHA"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e0900f3da58897fd209d64081d3031deeb7de3d74b04d540bcaacc585fcac50"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ssc-paper': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
